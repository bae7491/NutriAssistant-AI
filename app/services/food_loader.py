from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional
import time
import re
import logging
import sys

import numpy as np
import pandas as pd

from app.core.config import (
    INTERNAL_API_KEY,
    SPRING_FOOD_API,
    SPRING_PAGE_SIZE,
    SPRING_TIMEOUT_SECONDS,
    ROLE_ORDER,
    NUM_COLS,
    DESSERT_CATEGORIES,
)
from app.utils.text import get_role

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

try:
    import requests  # type: ignore
except Exception:  # pragma: no cover
    requests = None


@dataclass
class FoodContext:
    ready: bool
    pools: Dict[str, pd.DataFrame]
    pool_matrices: Dict[str, np.ndarray]
    pool_display_names: Dict[str, np.ndarray]
    pool_cats: Dict[str, np.ndarray]
    pool_allergies: Dict[str, np.ndarray]
    default_rice_idx: int
    gene_space: List[List[int]]
    source: str
    dessert_pool: List[str]
    dessert_allergies: Dict[str, str]  # ë””ì €íŠ¸ ë©”ë‰´ëª… â†’ ì•Œë ˆë¥´ê¸° ì •ë³´ ë§¤í•‘
    last_error: Optional[str] = None
    load_timestamp: Optional[str] = None  # ë¡œë“œ ì‹œê°„ ì¶”ê°€
    memory_size_mb: Optional[float] = None  # ë©”ëª¨ë¦¬ í¬ê¸° ì¶”ê°€


_CTX: Optional[FoodContext] = None


def get_context() -> FoodContext:
    """ë©”ëª¨ë¦¬ì— ìºì‹±ëœ ìŒì‹ DB ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜"""
    if _CTX is None or not _CTX.ready:
        raise RuntimeError("dataset not ready")
    return _CTX


def get_context_stats() -> Dict[str, Any]:
    """ì»¨í…ìŠ¤íŠ¸ í†µê³„ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…ìš©)"""
    if _CTX is None:
        return {"status": "not_loaded", "error": "Context has not been initialized"}

    if not _CTX.ready:
        return {"status": "error", "error": _CTX.last_error, "source": _CTX.source}

    # ì—­í• ë³„ í†µê³„
    role_stats = {}
    total_menus = 0
    for role, pool in _CTX.pools.items():
        count = len(pool)
        total_menus += count
        role_stats[role] = {
            "count": count,
            "sample_menus": pool["menuName"].head(3).tolist() if not pool.empty else [],
        }

    # ì˜ì–‘ì†Œ ë²”ìœ„ ê³„ì‚°
    nutrition_ranges = {}
    for col in NUM_COLS:
        all_values = []
        for pool in _CTX.pools.values():
            if col in pool.columns:
                all_values.extend(pool[col].dropna().tolist())

        if all_values:
            nutrition_ranges[col] = {
                "min": float(np.min(all_values)),
                "max": float(np.max(all_values)),
                "mean": float(np.mean(all_values)),
            }

    return {
        "status": "ready",
        "source": _CTX.source,
        "load_timestamp": _CTX.load_timestamp,
        "memory_size_mb": _CTX.memory_size_mb,
        "total_menus": total_menus,
        "role_breakdown": role_stats,
        "dessert_pool_size": len(_CTX.dessert_pool),
        "dessert_samples": _CTX.dessert_pool[:5],
        "nutrition_ranges": nutrition_ranges,
        "gene_space_lengths": [len(space) for space in _CTX.gene_space],
    }


def _require_requests() -> None:
    if requests is None:
        raise RuntimeError("requests íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install requests`")


def fetch_foodinfo_all_from_spring() -> pd.DataFrame:
    """Spring APIì—ì„œ ëª¨ë“  ìŒì‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    _require_requests()

    logger.info(f"ğŸ”„ Spring APIì—ì„œ ìŒì‹ DB ë¡œë”© ì‹œì‘: {SPRING_FOOD_API}")

    rows: List[Dict[str, Any]] = []
    page = 0
    size = SPRING_PAGE_SIZE

    headers: Dict[str, str] = {}
    if INTERNAL_API_KEY:
        headers["X-Internal-API-Key"] = INTERNAL_API_KEY
        logger.info(f"   ğŸ”‘ API Key ì„¤ì •ë¨ (ê¸¸ì´: {len(INTERNAL_API_KEY)})")
    else:
        logger.warning("   âš ï¸ INTERNAL_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

    def _unwrap(obj: Any) -> Any:
        while isinstance(obj, dict):
            for k in ("data", "result", "payload"):
                v = obj.get(k)
                if isinstance(v, (dict, list)):
                    obj = v
                    break
            else:
                break
        return obj

    start_time = time.time()
    total_fetched = 0

    while True:
        try:
            resp = requests.get(
                SPRING_FOOD_API,
                params={"page": page, "size": size},
                headers=headers,
                timeout=SPRING_TIMEOUT_SECONDS,
            )
            resp.raise_for_status()
        except Exception as e:
            logger.error(f"âŒ Spring API ìš”ì²­ ì‹¤íŒ¨ (page={page}): {e}")
            raise RuntimeError(f"Spring API ìš”ì²­ ì‹¤íŒ¨: {e}")

        try:
            data: Any = resp.json()
        except Exception as e:
            logger.error(f"âŒ Spring API JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"Spring API JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

        data = _unwrap(data)

        batch: List[Dict[str, Any]] = []
        is_last = True

        if isinstance(data, dict):
            content = data.get("content")
            if isinstance(content, list):
                batch = content
                is_last = bool(data.get("last", False))
            else:
                for k in ("items", "rows", "list"):
                    v = data.get(k)
                    if isinstance(v, list):
                        batch = v
                        is_last = True
                        break
                if not batch:
                    raise RuntimeError(
                        f"Spring ì‘ë‹µì— content/items/rows/listê°€ ì—†ìŠµë‹ˆë‹¤. keys={list(data.keys())}"
                    )
        elif isinstance(data, list):
            batch = data
            is_last = True
        else:
            raise RuntimeError(f"Spring ì‘ë‹µ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: type={type(data)}")

        if not batch:
            break

        rows.extend(batch)
        total_fetched += len(batch)

        logger.info(
            f"   ğŸ“„ Page {page}: {len(batch)}ê°œ ë¡œë“œë¨ (ëˆ„ì : {total_fetched}ê°œ)"
        )

        if is_last:
            break
        page += 1

    elapsed = time.time() - start_time
    logger.info(
        f"âœ… Spring API ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {total_fetched}ê°œ (ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ)"
    )

    return pd.DataFrame(rows)


def _extract_number(val: Any, default: float = 100.0) -> float:
    """ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
    if val is None:
        return default
    s = str(val)
    m = re.findall(r"[-+]?\d*\.\d+|\d+", s)
    if not m:
        return default
    try:
        return float(m[0])
    except Exception:
        return default


def _calculate_memory_size(ctx: FoodContext) -> float:
    """ì»¨í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ ë©”ëª¨ë¦¬ í¬ê¸° ê³„ì‚° (MB)"""
    try:
        total_bytes = 0

        # DataFrame í¬ê¸°
        for pool in ctx.pools.values():
            total_bytes += pool.memory_usage(deep=True).sum()

        # NumPy ë°°ì—´ í¬ê¸°
        for matrix in ctx.pool_matrices.values():
            total_bytes += matrix.nbytes

        for arr in ctx.pool_display_names.values():
            total_bytes += arr.nbytes

        for arr in ctx.pool_cats.values():
            total_bytes += arr.nbytes

        for arr in ctx.pool_allergies.values():
            total_bytes += arr.nbytes

        # ë””ì €íŠ¸ í’€
        total_bytes += sys.getsizeof(ctx.dessert_pool)

        return total_bytes / 1024 / 1024  # MBë¡œ ë³€í™˜

    except Exception as e:
        logger.warning(f"ë©”ëª¨ë¦¬ í¬ê¸° ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0


def load_spring_and_build_context() -> None:
    """Spring(MySQL) ê¸°ë°˜ food_infoë¥¼ ì½ì–´ pools/í–‰ë ¬/ë””ì €íŠ¸í’€ êµ¬ì„±"""
    global _CTX

    logger.info("=" * 80)
    logger.info("ğŸš€ ìŒì‹ DB ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ ì‹œì‘")
    logger.info("=" * 80)

    load_start_time = time.time()
    last_err: Optional[str] = None
    df: pd.DataFrame = pd.DataFrame([])

    # Spring APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì¬ì‹œë„ ë¡œì§)
    for attempt in range(1, 11):
        try:
            df = fetch_foodinfo_all_from_spring()
            if df is not None and not df.empty:
                last_err = None
                break
            last_err = "Spring food APIê°€ ë¹ˆ ë°ì´í„°ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
            logger.warning(f"âš ï¸ ì‹œë„ {attempt}/10: {last_err}")
        except Exception as e:
            last_err = str(e)
            logger.warning(f"âš ï¸ ì‹œë„ {attempt}/10 ì‹¤íŒ¨: {last_err}")

        if attempt < 10:
            wait_time = min(attempt, 10)
            logger.info(f"   â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(wait_time)

    if df.empty:
        logger.error(f"âŒ ìŒì‹ DB ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {last_err}")
        _CTX = FoodContext(
            ready=False,
            pools={},
            pool_matrices={},
            pool_display_names={},
            pool_cats={},
            pool_allergies={},
            default_rice_idx=0,
            gene_space=[],
            source=SPRING_FOOD_API,
            dessert_pool=[],
            dessert_allergies={},
            last_error=last_err,
            load_timestamp=None,
            memory_size_mb=0.0,
        )
        return

    logger.info(f"ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ (ì´ {len(df)}ê°œ í–‰)")

    def _pick(*names: str) -> pd.Series:
        for n in names:
            if n in df.columns:
                return df[n]
        return pd.Series([None] * len(df))

    merged = df.copy()

    # ì»¬ëŸ¼ ë§¤í•‘
    merged["menuName"] = _pick("foodName", "food_name", "name").fillna("").astype(str)
    merged["category"] = (
        _pick("category", "ì‹í’ˆëŒ€ë¶„ë¥˜ëª…", "foodCategory").fillna("").astype(str)
    )
    merged["allergy"] = (
        _pick("allergyInfo", "allergy_info", "allergy").fillna("").astype(str)
    )

    # ì˜ì–‘ì†Œ ì •ê·œí™”
    merged["kcal"] = pd.to_numeric(_pick("kcal", "energy"), errors="coerce").fillna(0)
    merged["carbs"] = pd.to_numeric(
        _pick("carbs", "carbohydrate"), errors="coerce"
    ).fillna(0)
    merged["protein"] = pd.to_numeric(_pick("protein"), errors="coerce").fillna(0)
    merged["fat"] = pd.to_numeric(_pick("fat"), errors="coerce").fillna(0)
    merged["calcium"] = pd.to_numeric(_pick("calcium"), errors="coerce").fillna(0)
    merged["iron"] = pd.to_numeric(_pick("iron"), errors="coerce").fillna(0)
    merged["vitaminA"] = pd.to_numeric(
        _pick("vitaminA", "vitamin_a"), errors="coerce"
    ).fillna(0)
    merged["vitaminC"] = pd.to_numeric(
        _pick("vitaminC", "vitamin_c"), errors="coerce"
    ).fillna(0)

    # 1ì¸ë¶„ í™˜ì‚°
    basis = _pick("servingBasis", "ì˜ì–‘ì„±ë¶„í•¨ëŸ‰ê¸°ì¤€ëŸ‰")
    weight = _pick("foodWeight", "ì‹í’ˆì¤‘ëŸ‰")
    if basis is not None and weight is not None:
        base_vals = basis.apply(lambda x: _extract_number(x, 100.0)).replace(0, 100.0)
        serve_vals = weight.apply(lambda x: _extract_number(x, 100.0)).replace(0, 100.0)
        ratio = (serve_vals / base_vals).replace([np.inf, -np.inf], 1.0).fillna(1.0)
        for c in NUM_COLS:
            merged[c] = (merged[c] * ratio).fillna(0)
        logger.info("   âœ… 1ì¸ë¶„ ê¸°ì¤€ ì˜ì–‘ì†Œ í™˜ì‚° ì™„ë£Œ")

    # ë””ì €íŠ¸ í’€ ë¶„ë¦¬ (ì•Œë ˆë¥´ê¸° ì •ë³´ í¬í•¨)
    dessert_mask = merged["category"].astype(str).str.strip().isin(DESSERT_CATEGORIES)
    dessert_df = merged.loc[dessert_mask, ["menuName", "allergy"]].dropna(
        subset=["menuName"]
    )
    dessert_df["menuName"] = dessert_df["menuName"].astype(str).str.strip()
    dessert_df["allergy"] = dessert_df["allergy"].fillna("").astype(str)

    # ì¤‘ë³µ ì œê±° (ì²« ë²ˆì§¸ ë“±ì¥ ê¸°ì¤€)
    dessert_df = dessert_df.drop_duplicates(subset=["menuName"], keep="first")

    dessert_pool = dessert_df["menuName"].tolist()
    dessert_allergies = dict(zip(dessert_df["menuName"], dessert_df["allergy"]))
    logger.info(f"ğŸ° ë””ì €íŠ¸/ìŒë£Œ í’€ ë¶„ë¦¬: {len(dessert_pool)}ê°œ")

    # ì¼ë°˜ ë©”ë‰´ í›„ë³´
    candidates = merged.loc[~dessert_mask].copy()
    candidates["role"] = candidates["category"].apply(get_role)
    candidates = candidates.dropna(subset=["role"]).copy()

    for c in NUM_COLS:
        candidates[c] = pd.to_numeric(candidates[c], errors="coerce").fillna(0)

    # ì—­í• ë³„ í’€ ìƒì„±
    unique_roles = list(dict.fromkeys(ROLE_ORDER))
    pools = {
        r: candidates[candidates["role"] == r].reset_index(drop=True)
        for r in unique_roles
    }

    # ì—­í• ë³„ ë©”ë‰´ ìˆ˜ ë¡œê¹…
    logger.info("ğŸ“‹ ì—­í• ë³„ ë©”ë‰´ ìˆ˜:")
    for role, pool in pools.items():
        logger.info(f"   - {role}: {len(pool)}ê°œ")

    missing = [r for r in unique_roles if r not in pools or pools[r].empty]
    if missing:
        error_msg = f"ì—­í• ë³„ poolì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {', '.join(missing)}"
        logger.error(f"âŒ {error_msg}")
        _CTX = FoodContext(
            ready=False,
            pools={},
            pool_matrices={},
            pool_display_names={},
            pool_cats={},
            pool_allergies={},
            default_rice_idx=0,
            gene_space=[],
            source=SPRING_FOOD_API,
            dessert_pool=dessert_pool,
            dessert_allergies=dessert_allergies,
            last_error=error_msg,
            load_timestamp=None,
            memory_size_mb=0.0,
        )
        return

    # í–‰ë ¬ ë° ë°°ì—´ ìƒì„±
    pool_matrices = {r: pools[r][NUM_COLS].values for r in pools}
    pool_display_names = {r: pools[r]["menuName"].values for r in pools}
    pool_cats = {r: pools[r]["category"].values for r in pools}
    pool_allergies = {
        r: pools[r]["allergy"].fillna("").astype(str).values for r in pools
    }

    gene_space = [list(range(len(pools[r]))) for r in ROLE_ORDER]

    # ê¸°ë³¸ ìŒ€ë°¥ ì¸ë±ìŠ¤ ì°¾ê¸°
    default_rice_idx = 0
    try:
        default_rice_idx = next(
            i
            for i, n in enumerate(pool_display_names["ë°¥"])
            if "ìŒ€ë°¥" in str(n) or "í°ë°¥" in str(n)
        )
        logger.info(f"   âœ… ê¸°ë³¸ ìŒ€ë°¥ ì¸ë±ìŠ¤: {default_rice_idx}")
    except Exception:
        logger.warning("   âš ï¸ ê¸°ë³¸ ìŒ€ë°¥ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ 0 ì‚¬ìš©")
        default_rice_idx = 0

    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    from datetime import datetime

    load_timestamp = datetime.now().isoformat()

    _CTX = FoodContext(
        ready=True,
        pools=pools,
        pool_matrices=pool_matrices,
        pool_display_names=pool_display_names,
        pool_cats=pool_cats,
        pool_allergies=pool_allergies,
        default_rice_idx=default_rice_idx,
        gene_space=gene_space,
        source=SPRING_FOOD_API,
        dessert_pool=dessert_pool,
        dessert_allergies=dessert_allergies,
        last_error=None,
        load_timestamp=load_timestamp,
        memory_size_mb=0.0,  # ì„ì‹œê°’
    )

    # ë©”ëª¨ë¦¬ í¬ê¸° ê³„ì‚°
    _CTX.memory_size_mb = _calculate_memory_size(_CTX)

    load_elapsed = time.time() - load_start_time

    logger.info("=" * 80)
    logger.info("âœ… ìŒì‹ DB ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ ì™„ë£Œ!")
    logger.info(f"   - ì´ ë©”ë‰´ ìˆ˜: {sum(len(p) for p in pools.values())}ê°œ")
    logger.info(f"   - ë””ì €íŠ¸/ìŒë£Œ: {len(dessert_pool)}ê°œ")
    logger.info(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {_CTX.memory_size_mb:.2f} MB")
    logger.info(f"   - ì†Œìš” ì‹œê°„: {load_elapsed:.2f}ì´ˆ")
    logger.info(f"   - ë¡œë“œ ì‹œê°: {load_timestamp}")
    logger.info("=" * 80)


def get_valid_menu_names() -> List[str]:
    """
    DBì—ì„œ ìœ íš¨í•œ ë©”ë‰´ëª… ëª©ë¡ ì¡°íšŒ

    Returns:
        ë©”ë‰´ëª… ë¦¬ìŠ¤íŠ¸
    """
    ctx = get_context()

    # ëª¨ë“  ì—­í• ì˜ ë©”ë‰´ëª…ì„ í•©ì¹¨
    valid_names = []
    for role in ["ë°¥", "êµ­", "ì£¼ì°¬", "ë¶€ì°¬", "ê¹€ì¹˜", "ë””ì €íŠ¸"]:
        if role in ctx.pool_display_names:
            valid_names.extend(ctx.pool_display_names[role].tolist())

    # ë””ì €íŠ¸ë„ ì¶”ê°€
    if ctx.dessert_pool:
        valid_names.extend(ctx.dessert_pool)

    # ì¤‘ë³µ ì œê±°
    valid_names = list(set(valid_names))

    return valid_names


def build_context_with_new_menus(new_menus: List[Dict[str, Any]]) -> FoodContext:
    """
    ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ì— ì‹ ë©”ë‰´ë¥¼ ë³‘í•©í•œ ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„±

    Args:
        new_menus: ì‹ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸ (NewMenuInput í˜•íƒœì˜ dict)

    Returns:
        ì‹ ë©”ë‰´ê°€ ë³‘í•©ëœ FoodContext
    """
    import copy
    from app.utils.text import get_role

    base_ctx = get_context()

    if not new_menus:
        return base_ctx

    logger.info("=" * 60)
    logger.info(f"ğŸ†• ì‹ ë©”ë‰´ {len(new_menus)}ê°œ ë³‘í•© ì‹œì‘")
    logger.info("=" * 60)

    # ê¹Šì€ ë³µì‚¬ë¡œ ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´
    new_pools = {role: pool.copy() for role, pool in base_ctx.pools.items()}
    new_dessert_pool = list(base_ctx.dessert_pool)
    new_dessert_allergies = dict(base_ctx.dessert_allergies)

    # ë””ì €íŠ¸ ì¹´í…Œê³ ë¦¬ ëª©ë¡
    from app.core.config import DESSERT_CATEGORIES, NUM_COLS

    added_count = {"dessert": 0, "meal": 0}

    for menu in new_menus:
        food_name = menu.get("food_name", "").strip()
        category = menu.get("category", "").strip()
        allergy = menu.get("allergy_info", "") or ""

        if not food_name:
            logger.warning(f"   âš ï¸ ì‹ ë©”ë‰´ ìŠ¤í‚µ (ì´ë¦„ ì—†ìŒ): {menu}")
            continue

        # ë””ì €íŠ¸/ìŒë£Œ ì¹´í…Œê³ ë¦¬ì¸ ê²½ìš°
        if category in DESSERT_CATEGORIES:
            if food_name not in new_dessert_pool:
                new_dessert_pool.append(food_name)
                new_dessert_allergies[food_name] = str(allergy)
                added_count["dessert"] += 1
                logger.info(f"   ğŸ° ë””ì €íŠ¸ ì¶”ê°€: {food_name} ({category})")
        else:
            # ì¼ë°˜ ë©”ë‰´ - ì—­í•  ê²°ì •
            role = get_role(category)
            if role is None:
                logger.warning(f"   âš ï¸ ì—­í•  ë§¤í•‘ ì‹¤íŒ¨: {food_name} ({category})")
                continue

            if role not in new_pools:
                logger.warning(f"   âš ï¸ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—­í• : {role}")
                continue

            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing_names = new_pools[role]["menuName"].tolist()
            if food_name in existing_names:
                logger.info(f"   â„¹ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë©”ë‰´ ìŠ¤í‚µ: {food_name}")
                continue

            # ìƒˆ í–‰ ì¶”ê°€
            new_row = {
                "menuName": food_name,
                "category": category,
                "allergy": str(allergy),
                "kcal": float(menu.get("kcal", 0)),
                "carbs": float(menu.get("carbs", 0)),
                "protein": float(menu.get("protein", 0)),
                "fat": float(menu.get("fat", 0)),
                "calcium": float(menu.get("calcium", 0)),
                "iron": float(menu.get("iron", 0)),
                "vitaminA": float(menu.get("vitamin_a", 0)),
                "vitaminC": float(menu.get("vitamin_c", 0)),
                "role": role,
            }

            new_pools[role] = pd.concat(
                [new_pools[role], pd.DataFrame([new_row])],
                ignore_index=True,
            )
            added_count["meal"] += 1
            logger.info(f"   ğŸ½ï¸ {role} ì¶”ê°€: {food_name} ({category})")

    # í–‰ë ¬ ë° ë°°ì—´ ì¬ìƒì„±
    pool_matrices = {r: new_pools[r][NUM_COLS].values for r in new_pools}
    pool_display_names = {r: new_pools[r]["menuName"].values for r in new_pools}
    pool_cats = {r: new_pools[r]["category"].values for r in new_pools}
    pool_allergies = {
        r: new_pools[r]["allergy"].fillna("").astype(str).values for r in new_pools
    }

    # gene_space ì¬ìƒì„±
    gene_space = [list(range(len(new_pools[r]))) for r in ROLE_ORDER]

    # ê¸°ë³¸ ìŒ€ë°¥ ì¸ë±ìŠ¤
    default_rice_idx = base_ctx.default_rice_idx

    logger.info("=" * 60)
    logger.info(f"âœ… ì‹ ë©”ë‰´ ë³‘í•© ì™„ë£Œ")
    logger.info(f"   - ë””ì €íŠ¸ ì¶”ê°€: {added_count['dessert']}ê°œ")
    logger.info(f"   - ì¼ë°˜ ë©”ë‰´ ì¶”ê°€: {added_count['meal']}ê°œ")
    logger.info(f"   - ì´ ë””ì €íŠ¸ í’€: {len(new_dessert_pool)}ê°œ")
    for role, pool in new_pools.items():
        logger.info(f"   - {role}: {len(pool)}ê°œ")
    logger.info("=" * 60)

    return FoodContext(
        ready=True,
        pools=new_pools,
        pool_matrices=pool_matrices,
        pool_display_names=pool_display_names,
        pool_cats=pool_cats,
        pool_allergies=pool_allergies,
        default_rice_idx=default_rice_idx,
        gene_space=gene_space,
        source=base_ctx.source + " + new_menus",
        dessert_pool=new_dessert_pool,
        dessert_allergies=new_dessert_allergies,
        last_error=None,
        load_timestamp=base_ctx.load_timestamp,
        memory_size_mb=base_ctx.memory_size_mb,
    )
